---
title: "test scrittura"
output: html_document
date: "2023-02-18"
---

The goodness-of-fit problem occurs when we have a data set $\{x_i\}_{i=1}^{N}$ and we have to figure out whether the density distribution $p(x)$ of the data set is the same as the one of the given distribution $p_0(x)$.

Continuing the explanation in the summary of Friedman's paper, for the goodness-of-fit procedure we need to build the $H_0(t)$ distribution. To do so we need to: 

1. Draw a sample $z_t$ from the known distribution.

2. Train the model (in our case a logistic regression model) with the data set $\{u_i\}_{i=1}^{N+M}=\{x_i\}_{i=1}^{N} \cup \{z_{t_i}\}_{i=1}^{M}$ and obtain the scores $s_{t_i}$.

3. Collect the test statistic $t_l = T(\{s_{t_i}\}_{i=1}^{N}, \{s_{t_i}\}_{i=N + 1}^{N+M})$, that we are going to use as a null distribution.

# prova 

### First simulation $n_0 = 33$, $n_1 = 40$ and $k = 3$.
<div align="center"> <h4> <b> Fourth simulation: $n_0 = 94$, $n_1 = 90$ and $k = 10$. </b> </h4></div>



SPIEGA PCA

```{r}
pcaCharts <- function(x) {
    x.var <- x$sdev ^ 2
    x.pvar <- x.var/sum(x.var)
    # print("proportions of variance:")
    # print(x.pvar)
    
    par(mfrow=c(2,2))
    plot(x.pvar,xlab="Principal component", ylab="Proportion of variance explained", ylim=c(0,1), type='b')
    plot(cumsum(x.pvar),xlab="Principal component", ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b')
    screeplot(x)
    screeplot(x,type="l")
    par(mfrow=c(1,1))
}

```

```{r}
n0 <- 85
n1<- 93
alpha <- 0.05
k <- 5

aux <- prcomp(u[,1:(k*116)], center = T, scale = T)
pcaCharts(aux)

```


```{r}
k <- 10
PC <- aux$x[,1]  
for(i in (2:k))
  PC <- cbind(PC, aux$x[,i])

PC <- cbind(PC, Label = c(rep(1, 85), rep(0, 93)))
label <- c(rep(1, 85), rep(0, 93))
x <- PC[(1:85),(1:k)]
z <- PC[(86:178),(1:k)]

P <- 1000
t_l <- rep(NA, P)

# Simulation
for(i in (1:P)){  
  # Permutate the labels
  l <- sample(label, n0+n1)
  
  # Put the samples together with the permutated labels
  u_t <- rbind(cbind(x, Label = l[1:n0]), cbind(z, Label = l[(n0+1):(n0+n1)]))
      
  model <- glmnet(u_t[,(1:k)], l, family = "binomial", maxit = 80, alpha = 0.2)
  #model <- glm(Label ~ ., data = as.data.frame(u_t))
  # Get the model's scores
  score <- predict(model, u_t[,(1:k)], s = 0.05)
    
  # Find and save the test statistic computed on the scores
  t_l[i] <- ks.test(score[l == 0], score[l == 1])$statistic
}
```


```{r, echo=FALSE, fig.align='center'}
hist(t_l, xlim = c(0,1), col ='#D3BDB0')
abline(v=quantile(t_l, 1-alpha), lwd = 3, col = '#093824')

model <- glmnet(PC, l, family = "binomial", maxit = 80, alpha = 0.2)
#model <- glm(Label ~ ., data = as.data.frame(u_t))
# Get the model's scores
score <- predict(model, PC, s = 0.05)
abline(v=ks.test(score[1:n0], score[(n0+1):(n0+n1)])$statistic, col = '#71B48D', lwd =3)

```

```{r}
n0 <- 85
n1<- 93
alpha <- 0.05
k <- 15

PC <- aux$x[,1]  
for(i in (2:k))
  PC <- cbind(PC, aux$x[,i])

PC <- cbind(PC, Label = c(rep(1, 85), rep(0, 93)))

label <- c(rep(1, 85), rep(0, 93))
x <- PC[(1:85),(1:k)]
z <- PC[(86:178),(1:k)]

P <- 1000
t_l <- rep(NA, P)

# Simulation
for(i in (1:P)){  
  # Permutate the labels
  l <- sample(label, n0+n1)
  
  # Put the samples together with the permutated labels
  u_t <- rbind(cbind(x, Label = l[1:n0]), cbind(z, Label = l[(n0+1):(n0+n1)])) 
      
  # Train the model on the permutated data set
  model <- glm(Label ~ ., data = as.data.frame(u_t))
  # Get the model's scores
  score <- predict(model, as.data.frame(u_t))   
    
  # Find and save the test statistic computed on the scores
  t_l[i] <- ks.test(score[l == 0], score[l == 1])$statistic
}
```

```{r, echo=FALSE, fig.align='center'}
hist(t_l, xlim = c(0,1), col ='#D3BDB0')
abline(v=quantile(t_l, 1-alpha), lwd = 3, col = '#093824')

model <- glm(Label ~., data = as.data.frame(PC))
score <- predict(model, as.data.frame(PC))
abline(v=ks.test(score[1:n0], score[(n0+1):(n0+n1)])$statistic, col = '#71B48D', lwd =3)
```

```{r}
n0 <- 85
n1<- 93
alpha <- 0.05
k <- 20
 
PC <- aux$x[,1]  
for(i in (2:k))
  PC <- cbind(PC, aux$x[,i])

PC <- cbind(PC, Label = c(rep(1, 85), rep(0, 93)))

label <- c(rep(1, 85), rep(0, 93))
x <- PC[(1:85),(1:k)]
z <- PC[(86:178),(1:k)]

P <- 1000
t_l <- rep(NA, P)

# Simulation
for(i in (1:P)){  
  # Permutate the labels
  l <- sample(label, n0+n1)
  
  # Put the samples together with the permutated labels
  u_t <- rbind(cbind(x, Label = l[1:n0]), cbind(z, Label = l[(n0+1):(n0+n1)]))
      
  # Train the model on the permutated data set
  model <- glm(Label ~ ., data = as.data.frame(u_t))
  # Get the model's scores
  score <- predict(model, as.data.frame(u_t))   
    
  # Find and save the test statistic computed on the scores
  t_l[i] <- ks.test(score[l == 0], score[l == 1])$statistic
}
```


```{r, echo=FALSE, fig.align='center'}
hist(t_l, xlim = c(0,1), col ='#D3BDB0')
abline(v=quantile(t_l, 1-alpha), lwd = 3, col = '#093824')

model <- glm(Label ~., data = as.data.frame(PC))
score <- predict(model, as.data.frame(PC))
abline(v=ks.test(score[1:n0], score[(n0+1):(n0+n1)])$statistic, col = '#71B48D', lwd =3)
```


```{r}
n0 <- 85
n1<- 93
alpha <- 0.05
k <- 15

PC <- aux$x[,1]  
for(i in (2:k))
  PC <- cbind(PC, aux$x[,i])

PC <- cbind(PC, Label = c(rep(1, 85), rep(0, 93)))

label <- c(rep(1, 50), rep(0, n0-50))
x <- PC[(1:50),(1:k)]
z <- PC[(51:n0),(1:k)]
u_T <- cbind(rbind(x,z), Label = label)

P <- 1000
t_l <- rep(NA, P)

# Simulation
for(i in (1:P)){  
  # Permutate the labels
  l <- sample(label, n0)
  
  # Put the samples together with the permutated labels
  u_t <- rbind(cbind(x, Label = l[1:50]), cbind(z, Label = l[(51:n0)])) 
      
  # Train the model on the permutated data set
  model <- glm(Label ~ ., data = as.data.frame(u_t))
  # Get the model's scores
  score <- predict(model, as.data.frame(u_t))   
    
  # Find and save the test statistic computed on the scores
  t_l[i] <- ks.test(score[l == 0], score[l == 1])$statistic
}
```

```{r, echo=FALSE, fig.align='center'}
hist(t_l, xlim = c(0,1), col ='#D3BDB0')
abline(v=quantile(t_l, 1-alpha), lwd = 3, col = '#093824')

model <- glm(Label ~., data = as.data.frame(u_T))
score <- predict(model, as.data.frame(u_T))
abline(v=ks.test(score[(1:50)], score[(51:n0)])$statistic, col = '#71B48D', lwd =3)
```